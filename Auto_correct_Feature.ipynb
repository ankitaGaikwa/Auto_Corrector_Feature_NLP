{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "RdSqw_RWeMaR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pattern"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6BU4iyxg2VJ",
        "outputId": "a4cfa537-a4f2-48d7-8dcc-f408c033ad35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pattern in /usr/local/lib/python3.10/dist-packages (3.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pattern) (0.18.3)\n",
            "Requirement already satisfied: backports.csv in /usr/local/lib/python3.10/dist-packages (from pattern) (1.0.7)\n",
            "Requirement already satisfied: mysqlclient in /usr/local/lib/python3.10/dist-packages (from pattern) (2.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from pattern) (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pattern) (4.9.4)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.10/dist-packages (from pattern) (6.0.11)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from pattern) (20231228)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pattern) (3.8.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from pattern) (1.1.0)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.10/dist-packages (from pattern) (18.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pattern) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->pattern) (2.5)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (10.0.0)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (3.2.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (10.1.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (3.0.post1)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (5.0.1)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser->pattern) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (42.0.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx->pattern) (4.11.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (2024.2.2)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.10/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (4.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.16.0)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.10/dist-packages (from portend>=2.1.1->cherrypy->pattern) (5.5.1)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.10/dist-packages (from jaraco.collections->cherrypy->pattern) (3.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zc.lockfile->cherrypy->pattern) (67.7.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.22)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2023.4)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.3.0)\n",
            "Requirement already satisfied: autocommand in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.2.2)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (7.0.0)\n",
            "Requirement already satisfied: backports.tarfile in /usr/local/lib/python3.10/dist-packages (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->pattern) (1.0.0)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.6.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing regular expression\n",
        "import re\n",
        "\n",
        "# words\n",
        "w = []\n",
        "\n",
        "# reading text file\n",
        "with open('final.txt', 'r', encoding=\"utf8\") as f:\n",
        "\tfile_name_data = f.read()\n",
        "\tfile_name_data = file_name_data.lower()\n",
        "\tw = re.findall('\\w+', file_name_data)\n",
        "\n",
        "# vocabulary\n",
        "main_set = set(w)\n"
      ],
      "metadata": {
        "id": "t4MUvMs8tXEA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Frequency\n",
        "def counting_words(words):\n",
        "\tword_count = {}\n",
        "\tfor word in words:\n",
        "\t\tif word in word_count:\n",
        "\t\t\tword_count[word] += 1\n",
        "\t\telse:\n",
        "\t\t\tword_count[word] = 1\n",
        "\treturn word_count\n"
      ],
      "metadata": {
        "id": "lsm684a6gTjc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probablity of each word\n",
        "def prob_cal(word_count_dict):\n",
        "\tprobs = {}\n",
        "\tm = sum(word_count_dict.values())\n",
        "\tfor key in word_count_dict.keys():\n",
        "\t\tprobs[key] = word_count_dict[key] / m\n",
        "\treturn probs\n"
      ],
      "metadata": {
        "id": "rKsbpRccgZmz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "ixdD3bBrucu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LemmWord: extracting and adding\n",
        "# root word i.e.Lemma using pattern module\n",
        "import pattern\n",
        "from pattern.en import lemma, lexeme\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def LemmWord(word):\n",
        "\treturn list(lexeme(wd) for wd in word.split())[0]\n"
      ],
      "metadata": {
        "id": "QS8w2b-cgcGL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deletion of Letter"
      ],
      "metadata": {
        "id": "TBqI91E1ubCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting letters from the words\n",
        "def DeleteLetter(word):\n",
        "\tdelete_list = []\n",
        "\tsplit_list = []\n",
        "\tfor i in range(len(word)):\n",
        "\t\tsplit_list.append((word[0:i], word[i:]))\n",
        "\n",
        "\tfor a, b in split_list:\n",
        "\t\tdelete_list.append(a + b[1:])\n",
        "\treturn delete_list"
      ],
      "metadata": {
        "id": "ryGsPL1Uggwc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Switching of letter"
      ],
      "metadata": {
        "id": "ClL3xo2puk7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Switching two letters in a word\n",
        "def Switch_(word):\n",
        "\tsplit_list = []\n",
        "\tswitch_l = []\n",
        "\tfor i in range(len(word)):\n",
        "\t\tsplit_list.append((word[0:i], word[i:]))\n",
        "\tswitch_l = [a + b[1] + b[0] + b[2:] for a, b in split_list if len(b) >= 2]\n",
        "\treturn switch_l\n"
      ],
      "metadata": {
        "id": "sQZlHhVOgjCc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replace of Letter"
      ],
      "metadata": {
        "id": "tA8NCfv2urpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Replace_(word):\n",
        "\tsplit_l = []\n",
        "\treplace_list = []\n",
        "\n",
        "\tfor i in range(len(word)):\n",
        "\t\tsplit_l.append((word[0:i], word[i:]))\n",
        "\talphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\treplace_list = [a + l + (b[1:] if len(b) > 1 else '')\n",
        "\t\t\t\t\tfor a, b in split_l if b for l in alphs]\n",
        "\treturn replace_list\n"
      ],
      "metadata": {
        "id": "mrODvQ2MhJhN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_(word):\n",
        "\tsplit_l = []\n",
        "\tinsert_list = []\n",
        "\n",
        "\t# Making pairs of the split words\n",
        "\tfor i in range(len(word) + 1):\n",
        "\t\tsplit_l.append((word[0:i], word[i:]))\n",
        "\n",
        "\talphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\tinsert_list = [a + l + b for a, b in split_l for l in alphs]\n",
        "\treturn insert_list\n"
      ],
      "metadata": {
        "id": "0cjq6Gk6hLJk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def colab_1(word, allow_switches=True):\n",
        "\tcolab_1 = set()\n",
        "\tcolab_1.update(DeleteLetter(word))\n",
        "\tif allow_switches:\n",
        "\t\tcolab_1.update(Switch_(word))\n",
        "\tcolab_1.update(Replace_(word))\n",
        "\tcolab_1.update(insert_(word))\n",
        "\treturn colab_1\n",
        "\n",
        "# collecting words using by allowing switches\n",
        "def colab_2(word, allow_switches=True):\n",
        "\tcolab_2 = set()\n",
        "\tedit_one = colab_1(word, allow_switches=allow_switches)\n",
        "\tfor w in edit_one:\n",
        "\t\tif w:\n",
        "\t\t\tedit_two = colab_1(w, allow_switches=allow_switches)\n",
        "\t\t\tcolab_2.update(edit_two)\n",
        "\treturn colab_2\n"
      ],
      "metadata": {
        "id": "ACtOX7-0hN5s"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only storing those values which are in the vocab\n",
        "def get_corrections(word, probs, vocab, n=2):\n",
        "\tsuggested_word = []\n",
        "\tbest_suggestion = []\n",
        "\tsuggested_word = list(\n",
        "\t\t(word in vocab and word) or colab_1(word).intersection(vocab)\n",
        "\t\tor colab_2(word).intersection(\n",
        "\t\t\tvocab))\n",
        "\n",
        "\t# finding out the words with high frequencies\n",
        "\tbest_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
        "\treturn best_suggestion\n"
      ],
      "metadata": {
        "id": "CqDv3XXIhPs8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "my_word = input(\"Enter any word:\")\n",
        "\n",
        "# Counting word function\n",
        "word_count = counting_words(main_set)\n",
        "\n",
        "# Calculating probability\n",
        "probs = prob_cal(word_count)\n",
        "\n",
        "# only storing correct words\n",
        "tmp_corrections = get_corrections(my_word, probs, main_set, 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "\tif(i < 3):\n",
        "\t\tprint(word_prob[0])\n",
        "\telse:\n",
        "\t\tbreak\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OuLj49qhRlU",
        "outputId": "f41fc509-bb08-4770-f658-5c4fa34cb56b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter any word:prjct\n",
            "print\n",
            "prick\n",
            "price\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "RUUNpxjWhTw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}